import os
from langchain.document_loaders import PyPDFLoader, TextLoader
from langchain.text_splitter import CharacterTextSplitter
from langchain.vectorstores import FAISS
from langchain_google_genai import GoogleGenerativeAIEmbeddings


def ingest_file(file_path):
    ext = os.path.splitext(file_path)[1].lower()

    # ğŸ“„ Load PDF or TXT
    if ext == ".pdf":
        loader = PyPDFLoader(file_path)
    elif ext == ".txt":
        loader = TextLoader(file_path)
    else:
        raise ValueError("âŒ Only PDF or TXT files are supported.")

    docs = loader.load()

    # ğŸ”ª Chunk text into smaller parts
    splitter = CharacterTextSplitter(chunk_size=500, chunk_overlap=50)
    chunks = splitter.split_documents(docs)

    # ğŸ§¼ Remove empty or invalid chunks
    chunks = [chunk for chunk in chunks if chunk.page_content.strip()]

    if not chunks:
        raise ValueError("âŒ No usable content found in document after splitting.")

    # ğŸ” Create Embeddings
    embeddings = GoogleGenerativeAIEmbeddings(model="models/embedding-001")

    try:
        vectorstore = FAISS.from_documents(chunks, embeddings)
    except Exception as e:
        raise RuntimeError("âš ï¸ Gemini embedding failed. Try using a simpler or smaller file.") from e

    # ğŸ’¾ Save FAISS index
    vectorstore.save_local("modules/vectorstore")

    return "âœ… File indexed and ready to chat!"
